data:
  train_data: data/round2/prior/target_seqs_train.csv
  valid_data: data/round2/prior/target_seqs_test.csv
  max_len: 478
  column: sequence
  batch_size: 128
  num_workers: 4

model:
  n_layers: 8
  n_heads: 8
  n_embd: 256
  block_size: 500 # at least max_len + 2

train:
  n_epochs: 20
  learning_rate: 0.001
  lr_decay: True
  weight_decay: 0.1
  beta_1: 0.9
  beta_2: 0.95
  grad_norm_clip: 1.0
  device: cuda
  warmup_tokens: 5900     # max_len * n_batches_per_epoch * 0.1
  final_tokens: 1180000   # max_len * n_batches_per_epoch * n_epochs
  save_model: true
  seed: 42
  n_devices: 2
  